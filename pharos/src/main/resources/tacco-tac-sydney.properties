galagoUseLocalIndex=false
galagoIndexDir=/iesl/local/jdalton/freebase-wex-all
galagoJsonParameterFile=./config/galago-fullwiki


# galago server for http requests
galagoSrv=localhost

# galago server port for http requests
# -- search only anchor text and titles
galagoPort=10002
# -- full search
galagoPort=10002
# ------------------------------------

# max number of candidates returned by candidate generator      
candidates.maxCandidates=10
useTacAndFullWiki=false
candidates.maxNuissanceCandidates=5
neighborhood.maxClosestNuissanceMentions=10

useCachedCandidatesFromRunFile=false
candidateFileKey=default
neighborCandidateFileKey=neighbor
neighborTrainCandidateFileKey=neighborTrain
galagoRunDir=candidates



# query for candidates
candidates.queryType=seqdep
features.redisFeatureSetName=rank # nonlp,llcsurf,galago
features.redisFeatureSetName.entity2entity=neighbor # umassText
features.redisFeaturePort=6380
features.redisFeatureSvr=avon3

# If true, precomputed features will be loaded from redis, otherwise they will be loaded on the fly
features.useCachedFeatures=false
features.useCachedFeatures.e2e=false
# if true existing feature vectors will be regenerated and overwritten.
features.redisOverwriteExisting=false
features.redisOverwriteExisting.e2e=false
# ---------------------


# max number of training examples considered  -- omit or use -1 for no restrictions    
pipeline.numTrainQueries=-1
# max number of test examples considered  -- omit or use -1 for no restrictions
pipeline.numTestQueries=-1

pipeline.crossval=false

# if true, model will be trained; if false parameters are loaded from disc
pipeline.retrainModel=true


# which feature sets to use for ranking. example: "nus,llcsurc" for NUS and LLC's surface features
features.ranking=nonlp,llcsurf,galago
features.nil=nonlp,llcsurf,galago
features.neighborlinking=umassText



#  path to tab separated file for entity id conversion
idmapping=/work1/allan/jdalton/tac/tac-wiki-mapping

####### NLP Preprocessing
# path to extraction results (xml) from Stanford CoreNLP pipeline
# (copy from blake:/iesl/canvas/dietz/tacnlpextract/stanf/*.xml)
nlpextract.pathstanford=/work1/allan/jdalton/tac/tacnlpextract/stanf-sam2/
#nlpextract.pathstanford=/iesl/canvas/harshal/tacnlpextract/stanf-tacandfull_bkp/
nlpextract.outputpathstanford=/work1/allan/jdalton/tac/tmp/

# file that collects filenames to be extracted
nlpextract.liststanford=/work1/allan/jdalton/tac/tacnlpextract/extractStanfList-sam.txt
# Shell script for NLP processing will be written here
nlpextract.scriptstanford=/work1/allan/jdalton/tac/tacnlpextract/extractStanf.sh
# path to stanford extractor (needed only for shell script creation)
#nlpextract.execstanford=/iesl/canvas/jdalton/development/git/tacco/lib/stanford-corenlp-2012-04-09

serialcomention.path=/work1/allan/jdalton/tac/data/generatedFeatures/

galago.termcounts=/mnt/nfs/work1/jdalton/tac/full-wiki-stats

filterNoNlpInfo=false
eval.printranking=true
debug.parallelProcessing=false
pipeline.modelFile=neighbormodel
eval.detailedOutput=neighbor100.txt
useKbaNlpReader=true