# DEBUG:
debug.parallelProcessing=false

# add the correct candidate to the result set
useOracleCandidateGeneration=true

filterNoNlpInfo=false

# whether to use a local galago index (requires localIndexDir if true, galago server / port if false)
galagoUseLocalIndex=false

#localIndexDir
galagoIndexDir=/iesl/local/jdalton/freebase-wex-all

# galago server for http requests
galagoSrv=swarm

# galago server port for http requests   
galagoPort=10005

# max number of candidates returned by candidate generator      
candidates.maxCandidates=10


# query for candidates
# -- query type
# -- phrase query: "ord"
# -- prms query: "prms"
# -- or "default"
#candidates.queryType=od
# -- fields to include in the query, comma-separated:  "anchor,title,redirects,fbnames"
#candidates.queryFields=anchor,title
# -- example prms config
candidates.queryType=sdm
candidates.queryFields=anchor,title,redirects,fbnames
# ---------------------



# max number of training examples considered  -- omit or use -1 for no restrictions    
pipeline.numTrainQueries=100

# max number of test examples considered  -- omit or use -1 for no restrictions    
pipeline.numTestQueries=-1

pipeline.crossval=true

# which feature sets to use for ranking. example: "nus,llcsurc" for NUS and LLC's surface features
features.ranking=galago
# which feature set to use for nils classify
features.nil=galago

#  path to tab separated file for entity id conversion
idmapping=/work1/allan/jdalton/entity-linking/tac-wiki-mapping2

###### wili: wiki-links. documents and web pages that link into wikipedia
# parent directory of raw pages that link into wikipedia
wili.files=/iesl/canvas/martin/wiki-link/retrieve/pages
# path to anchor text and link structure
wili.links=/iesl/canvas/sameer/dat/wiki-link/data-00000-of-00001
# file id (as line number) to filename
wili.fileids=/iesl/canvas/martin/wiki-link/retrieve/wiki-link-urls.dat

# number of webpage records to load from wili dataset
wili.restrictPages=10000



##### OBSOLETE
lbj.config=/iesl/canvas/dietz/development/git/tacco/lbjnertagger2/Config/allLayer1.config
# the path to the directory containing the "Data" directory for the lbj tagger (including slash)
lbj.datapath=/iesl/canvas/dietz/development/git/tacco/lbjnertagger2/
# url prefix to directory containing lbj/NETaggerLevel1.lc etc. This is in the LBJNerTagger2 project/bin/ (including slash)
lbj.lcPath=file:/iesl/canvas/dietz/development/git/tacco/lbjnertagger2/bin/




####### NLP Preprocessing
# path to extraction results (xml) from Stanford CoreNLP pipeline
# (copy from blake:/iesl/canvas/dietz/tacnlpextract/stanf/*.xml)
nlpextract.pathstanford=/iesl/canvas/dietz/tacnlpextract/newstanf/
nlpextract.oldpathstanford=/iesl/canvas/dietz/tacnlpextract/stanf/
# file that collects filenames to be extracted
nlpextract.liststanford=/iesl/canvas/dietz/tacnlpextract/extractStanfList.txt
# Shell script for NLP processing will be written here
nlpextract.scriptstanford=/iesl/canvas/dietz/tacnlpextract/extractStanf.sh
# path to stanford extractor (needed only for shell script creation)
nlpextract.execstanford=/iesl/canvas/dietz/development/git/tacco/lib/stanford-corenlp-2012-04-09

# What's this??
galago.termcounts=/iesl/canvas/dietz/development/git/tacco/termcounts.txt

